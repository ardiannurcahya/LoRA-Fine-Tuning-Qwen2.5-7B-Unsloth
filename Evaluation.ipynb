{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11f99bb4d6f043eaba564216ecd8c774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2e5c3fb4ea14f68ba8fd572985196e7",
              "IPY_MODEL_b9868e132ac0437a9da0e66cfbc3ba85",
              "IPY_MODEL_c1e85763a4c34784a33b8443e19efd20"
            ],
            "layout": "IPY_MODEL_7e5a62f7c8a043cbb4bb37ab6e10f6bf"
          }
        },
        "a2e5c3fb4ea14f68ba8fd572985196e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68af9272a2a04fd0962364cd88a01385",
            "placeholder": "​",
            "style": "IPY_MODEL_d1f80098db494cbe88f2b62ab667ecab",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b9868e132ac0437a9da0e66cfbc3ba85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfe854d36e05485387377cce806801f6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_078855eb5cc445688c0097da599658af",
            "value": 2
          }
        },
        "c1e85763a4c34784a33b8443e19efd20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96d278a76874b2485493e4863dba5b4",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f8b418ae1949bba63d62b9b1aa927f",
            "value": " 2/2 [00:23&lt;00:00, 11.59s/it]"
          }
        },
        "7e5a62f7c8a043cbb4bb37ab6e10f6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68af9272a2a04fd0962364cd88a01385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f80098db494cbe88f2b62ab667ecab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfe854d36e05485387377cce806801f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "078855eb5cc445688c0097da599658af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d96d278a76874b2485493e4863dba5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f8b418ae1949bba63d62b9b1aa927f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfb6fdea86da4811a89eb03f42953b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2431523f21704df580c47ddd977667b7",
              "IPY_MODEL_806cccbd34f7464ebb88abf8c75cd1ef",
              "IPY_MODEL_19a181c240454c9daccb8474333fbb25"
            ],
            "layout": "IPY_MODEL_c25e7f079fb24efaa8fd1660eaffb7b1"
          }
        },
        "2431523f21704df580c47ddd977667b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_194acd8e8db742629b00cdc9bc1cb360",
            "placeholder": "​",
            "style": "IPY_MODEL_bbbaba63183e4699bc9c9ff096bab968",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "806cccbd34f7464ebb88abf8c75cd1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32a02698ecd84bc2b8246c91951d992e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08e608153e524694b2e40ee0532d8cb6",
            "value": 2
          }
        },
        "19a181c240454c9daccb8474333fbb25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9440079fc9a3434e8628696478864206",
            "placeholder": "​",
            "style": "IPY_MODEL_1de2d6006791418c82e9d1c28df57058",
            "value": " 2/2 [00:29&lt;00:00, 14.40s/it]"
          }
        },
        "c25e7f079fb24efaa8fd1660eaffb7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194acd8e8db742629b00cdc9bc1cb360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbbaba63183e4699bc9c9ff096bab968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32a02698ecd84bc2b8246c91951d992e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e608153e524694b2e40ee0532d8cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9440079fc9a3434e8628696478864206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1de2d6006791418c82e9d1c28df57058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f75ad01c5d8544c8b8ba64e878983741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c71f9c4e29bd4210aace742d0fc18a5c",
              "IPY_MODEL_67d06962ef804ba5847ab373a88fd2c5",
              "IPY_MODEL_ac19bc54a35f424a93661524ae35dda0"
            ],
            "layout": "IPY_MODEL_287ff38b99fa425fa9cb68d914109e5f"
          }
        },
        "c71f9c4e29bd4210aace742d0fc18a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_108412346e434e8e902513ceceb9b31e",
            "placeholder": "​",
            "style": "IPY_MODEL_c807ae82da364527ab22ba5b9733e20b",
            "value": "Map: 100%"
          }
        },
        "67d06962ef804ba5847ab373a88fd2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce2ddec7f08f432882f82caea50a1217",
            "max": 4700,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e527208e7e1c490f8287bc29c0a593b5",
            "value": 4700
          }
        },
        "ac19bc54a35f424a93661524ae35dda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d74b41237945089efc1fd0c3afefd5",
            "placeholder": "​",
            "style": "IPY_MODEL_2896167efb76442692580d039566618d",
            "value": " 4700/4700 [00:00&lt;00:00, 10517.38 examples/s]"
          }
        },
        "287ff38b99fa425fa9cb68d914109e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "108412346e434e8e902513ceceb9b31e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c807ae82da364527ab22ba5b9733e20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce2ddec7f08f432882f82caea50a1217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e527208e7e1c490f8287bc29c0a593b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09d74b41237945089efc1fd0c3afefd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2896167efb76442692580d039566618d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e11b70897dde4fc1a4dbf630ac34fcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68fdcdff291b46d3aef2a212c9b2d04f",
              "IPY_MODEL_12f1f63083a147699d2bb9114dfd2b64",
              "IPY_MODEL_eedc549254294fb593198c659d319621"
            ],
            "layout": "IPY_MODEL_c47ee56029eb4d6387dae7892eaa94a1"
          }
        },
        "68fdcdff291b46d3aef2a212c9b2d04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4cdeb4aac074edfaeb725f201a655a0",
            "placeholder": "​",
            "style": "IPY_MODEL_ea5f8634726c48aa8509ec1a1484b6be",
            "value": "Map: 100%"
          }
        },
        "12f1f63083a147699d2bb9114dfd2b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27d4f03cac02466bbb9da0c5b55adb4c",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed5f9810a86f4e99b420f28450e3d857",
            "value": 300
          }
        },
        "eedc549254294fb593198c659d319621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fd1b71f66294f6fbdd70a77125dd5cf",
            "placeholder": "​",
            "style": "IPY_MODEL_3a4f0ffdc4d64db48ba4ffac1af80bdf",
            "value": " 300/300 [00:00&lt;00:00, 5627.27 examples/s]"
          }
        },
        "c47ee56029eb4d6387dae7892eaa94a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4cdeb4aac074edfaeb725f201a655a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea5f8634726c48aa8509ec1a1484b6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27d4f03cac02466bbb9da0c5b55adb4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5f9810a86f4e99b420f28450e3d857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fd1b71f66294f6fbdd70a77125dd5cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a4f0ffdc4d64db48ba4ffac1af80bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "RzcXDwpj6KLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ],
      "metadata": {
        "id": "py3HLNEqQxZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install rouge_score\n",
        "!pip install git+https://github.com/k4black/codebleu.git\n",
        "!pip install tree-sitter-python"
      ],
      "metadata": {
        "id": "sJcRnXyGDAd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Model"
      ],
      "metadata": {
        "id": "s8iZB3hY6M3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "# Memuat model dasar (base model)\n",
        "model_base, tokenizer_base = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"Qwen/Qwen2.5-7B\",  # Model dasar (base model) yang belum di-fine-tune\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        "    token=userdata.get('HF_TOKEN')\n",
        ")\n",
        "FastLanguageModel.for_inference(model_base)  # Mengaktifkan inferensi yang lebih cepat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2880,
          "referenced_widgets": [
            "11f99bb4d6f043eaba564216ecd8c774",
            "a2e5c3fb4ea14f68ba8fd572985196e7",
            "b9868e132ac0437a9da0e66cfbc3ba85",
            "c1e85763a4c34784a33b8443e19efd20",
            "7e5a62f7c8a043cbb4bb37ab6e10f6bf",
            "68af9272a2a04fd0962364cd88a01385",
            "d1f80098db494cbe88f2b62ab667ecab",
            "cfe854d36e05485387377cce806801f6",
            "078855eb5cc445688c0097da599658af",
            "d96d278a76874b2485493e4863dba5b4",
            "a6f8b418ae1949bba63d62b9b1aa927f"
          ]
        },
        "id": "iXQJ6DXl5nme",
        "outputId": "f7075894-a9c8-4f76-dc33-d898f65a712e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.4.1: Fast Qwen2 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11f99bb4d6f043eaba564216ecd8c774"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "      (2-3): 2 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "      (4): Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "      (5): Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "      (6): Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "      (7-24): 18 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "      (25-26): 2 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "      (27): Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lora Model"
      ],
      "metadata": {
        "id": "Udg7kARz6QL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17293,
          "referenced_widgets": [
            "bfb6fdea86da4811a89eb03f42953b8b",
            "2431523f21704df580c47ddd977667b7",
            "806cccbd34f7464ebb88abf8c75cd1ef",
            "19a181c240454c9daccb8474333fbb25",
            "c25e7f079fb24efaa8fd1660eaffb7b1",
            "194acd8e8db742629b00cdc9bc1cb360",
            "bbbaba63183e4699bc9c9ff096bab968",
            "32a02698ecd84bc2b8246c91951d992e",
            "08e608153e524694b2e40ee0532d8cb6",
            "9440079fc9a3434e8628696478864206",
            "1de2d6006791418c82e9d1c28df57058"
          ]
        },
        "collapsed": true,
        "id": "asnMyn1kQnOi",
        "outputId": "e19cd00d-6aef-4ad1-a495-44666bed49ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.4.1: Fast Qwen2 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfb6fdea86da4811a89eb03f42953b8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.4.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Qwen2ForCausalLM(\n",
              "      (model): Qwen2Model(\n",
              "        (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
              "        (layers): ModuleList(\n",
              "          (0-1): 2 x Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          )\n",
              "          (2-3): 2 x Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          )\n",
              "          (4): Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          )\n",
              "          (5): Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          )\n",
              "          (6): Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          )\n",
              "          (7-24): 18 x Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          )\n",
              "          (25-26): 2 x Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          )\n",
              "          (27): Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Memuat model LoRA yang sudah di-fine-tune\n",
        "model_lora, tokenizer_lora = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"ncardian/Qwen2.5-7B-data-coder-LoRA\",  # Model LoRA yang sudah di-fine-tune\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        "    token=userdata.get('HF_TOKEN')\n",
        ")\n",
        "FastLanguageModel.for_inference(model_lora)  # Mengaktifkan inferensi yang lebih cepat"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "G6Nl0Lk66Sd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer_lora.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset_path = \"/content/drive/MyDrive/Lora/dataset-pd-coder.json\"\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=dataset_path)\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.06)\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "f75ad01c5d8544c8b8ba64e878983741",
            "c71f9c4e29bd4210aace742d0fc18a5c",
            "67d06962ef804ba5847ab373a88fd2c5",
            "ac19bc54a35f424a93661524ae35dda0",
            "287ff38b99fa425fa9cb68d914109e5f",
            "108412346e434e8e902513ceceb9b31e",
            "c807ae82da364527ab22ba5b9733e20b",
            "ce2ddec7f08f432882f82caea50a1217",
            "e527208e7e1c490f8287bc29c0a593b5",
            "09d74b41237945089efc1fd0c3afefd5",
            "2896167efb76442692580d039566618d",
            "e11b70897dde4fc1a4dbf630ac34fcee",
            "68fdcdff291b46d3aef2a212c9b2d04f",
            "12f1f63083a147699d2bb9114dfd2b64",
            "eedc549254294fb593198c659d319621",
            "c47ee56029eb4d6387dae7892eaa94a1",
            "d4cdeb4aac074edfaeb725f201a655a0",
            "ea5f8634726c48aa8509ec1a1484b6be",
            "27d4f03cac02466bbb9da0c5b55adb4c",
            "ed5f9810a86f4e99b420f28450e3d857",
            "5fd1b71f66294f6fbdd70a77125dd5cf",
            "3a4f0ffdc4d64db48ba4ffac1af80bdf"
          ]
        },
        "id": "Jrjzi6DzyPTW",
        "outputId": "eadad8d0-9cde-4ef8-f6d9-921f735cbee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4700 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f75ad01c5d8544c8b8ba64e878983741"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e11b70897dde4fc1a4dbf630ac34fcee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output', 'text'],\n",
              "        num_rows: 4700\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['instruction', 'input', 'output', 'text'],\n",
              "        num_rows: 300\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quality Base Model Test"
      ],
      "metadata": {
        "id": "DPSLM7e86Uj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Aktifkan mode inference 2x lebih cepat\n",
        "FastLanguageModel.for_inference(model_base)\n",
        "\n",
        "# Template prompt ala Alpaca\n",
        "alpaca_prompt = (\n",
        "    \"### Instruction:\\n{instruction}\\n\\n\"\n",
        "    \"### Input:\\n{input}\\n\\n\"\n",
        "    \"### Response:\\n{output}\"\n",
        ")\n",
        "\n",
        "# Prompt generation\n",
        "prompt = alpaca_prompt.format(\n",
        "    instruction=\"Show plot No2 vs So2?\",\n",
        "    input='{ \"Date\": \"str\", \"Wspeed\": \"int\", \"NO2: \"float\", \"wd\": \"str\", \"SO2\": \"float\" }',\n",
        "    output=\"\"  # kosongkan untuk prompting\n",
        ")\n",
        "\n",
        "# Tokenisasi\n",
        "inputs = tokenizer_base([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Stream output\n",
        "text_streamer = TextStreamer(tokenizer_base)\n",
        "_ = model_base.generate(\n",
        "    **inputs,\n",
        "    streamer=text_streamer,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=True,\n",
        "    temperature=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQuKCANITkDK",
        "outputId": "c4c2f4e0-178d-462e-eeab-35fb4ef202d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "Show plot No2 vs So2?\n",
            "\n",
            "### Input:\n",
            "{ \"Date\": \"str\", \"Wspeed\": \"int\", \"NO2: \"float\", \"wd\": \"str\", \"SO2\": \"float\" }\n",
            "\n",
            "### Response:\n",
            "To show the plot of SO2 vs NO2, you can use the matplotlib library in Python. The code would look something like this:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Load the data into a dataframe\n",
            "data = pd.DataFrame({ \"Date\": \"str\", \"Wspeed\": \"int\", \"NO2\": \"float\", \"wd\": \"str\", \"SO2\": \"float\" })\n",
            "\n",
            "# Plot the data\n",
            "plt.scatter(data['NO2'], data['SO2'])\n",
            "plt.xlabel('NO2')\n",
            "plt.ylabel('SO2')\n",
            "plt.title('Plot of SO2 vs NO2')\n",
            "plt.show()\n",
            "```<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quality Lora Model Test"
      ],
      "metadata": {
        "id": "qh--x6oi6av5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Aktifkan mode inference 2x lebih cepat\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Template prompt ala Alpaca\n",
        "alpaca_prompt = (\n",
        "    \"### Instruction:\\n{instruction}\\n\\n\"\n",
        "    \"### Input:\\n{input}\\n\\n\"\n",
        "    \"### Response:\\n{output}\"\n",
        ")\n",
        "\n",
        "# Prompt generation\n",
        "prompt = alpaca_prompt.format(\n",
        "    instruction=\"Show plot No2 vs So2\",\n",
        "    input='{ \"Date\": \"str\", \"Wspeed\": \"int\", \"NO2: \"float\", \"wd\": \"str\", \"SO2\": \"float\" }',\n",
        "    output=\"\"  # kosongkan untuk prompting\n",
        ")\n",
        "\n",
        "# Tokenisasi\n",
        "inputs = tokenizer_lora([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Stream output\n",
        "text_streamer = TextStreamer(tokenizer_lora)\n",
        "_ = model_lora.generate(\n",
        "    **inputs,\n",
        "    streamer=text_streamer,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=True,\n",
        "    temperature=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIzkm8Qk5HXw",
        "outputId": "067410fb-f86d-4362-b717-35b289e80648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "Show plot No2 vs So2?\n",
            "\n",
            "### Input:\n",
            "{ \"Date\": \"str\", \"Wspeed\": \"int\", \"NO2: \"float\", \"wd\": \"str\", \"SO2\": \"float\" }\n",
            "\n",
            "### Response:\n",
            "# Import necessary libraries\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import plotly.express as px\n",
            "import plotly.graph_objects as go\n",
            "\n",
            "# Assume df is already loaded in memory\n",
            "\n",
            "# Data cleaning\n",
            "df = df.dropna()  # Remove missing values\n",
            "df = df.drop_duplicates()  # Remove duplicates\n",
            "\n",
            "# Scatter chart visualization\n",
            "fig = px.scatter(df, x='NO2', y='SO2', \n",
            "                 color='Date',\n",
            "                 title='Show plot No2 vs So2?')\n",
            "fig.show()\n",
            "<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark"
      ],
      "metadata": {
        "id": "etxpz44K6e_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "\n",
        "# Download the necessary data files for Punkt Tokenizer Model\n",
        "nltk.download('punkt_tab')\n",
        "from nltk import word_tokenize\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "test_data = dataset[\"test\"] #.shuffle(seed=42).select(range(100))\n",
        "\n",
        "from codebleu import calc_codebleu\n",
        "\n",
        "alpaca_prompt_template = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Answer the following question truthfully.\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "def codebleu_score(pred, target, lang='python'):\n",
        "    result = calc_codebleu([target], [pred], lang)\n",
        "    return result['codebleu']\n",
        "\n",
        "\n",
        "def generate_answer_alpaca_style(question):\n",
        "    prompt = alpaca_prompt_template.format(question)\n",
        "    # Tokenize the prompt and convert to tensor\n",
        "    inputs = tokenizer_lora(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # Generate response using the model\n",
        "    outputs = model_lora.generate(**inputs, max_new_tokens=512, use_cache=True)\n",
        "    # Decode the response to text\n",
        "    response = tokenizer_lora.decode(outputs[0], ignore_special_tokens=True)\n",
        "    return response.strip()\n",
        "\n",
        "def generate_answer_alpaca_style1(question):\n",
        "    prompt = alpaca_prompt_template.format(question)\n",
        "    # Tokenize the prompt and convert to tensor\n",
        "    inputs = tokenizer_base(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # Generate response using the model\n",
        "    outputs = model_base.generate(**inputs, max_new_tokens=512, use_cache=True)\n",
        "    # Decode the response to text\n",
        "    response = tokenizer_base.decode(outputs[0], ignore_special_tokens=True)\n",
        "    return response.strip()\n",
        "\n",
        "# Evaluator F1\n",
        "def f1_word_overlap(pred, target):\n",
        "    pred_tokens = set(word_tokenize(pred.lower()))\n",
        "    target_tokens = set(word_tokenize(target.lower()))\n",
        "    overlap = pred_tokens & target_tokens\n",
        "    if not target_tokens:\n",
        "        return 0.0\n",
        "    precision = len(overlap) / len(pred_tokens) if pred_tokens else 0\n",
        "    recall = len(overlap) / len(target_tokens)\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "# Evaluator ROUGE-L\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "def rouge_l_score(pred, target):\n",
        "    scores = scorer.score(target, pred)\n",
        "    return scores[\"rougeL\"].fmeasure\n",
        "\n",
        "# Fungsi utama benchmarking\n",
        "def benchmark_model(test_data, generate_func):\n",
        "    results = []\n",
        "    for item in tqdm(test_data):\n",
        "        if item['input']:\n",
        "            question = f\"{item['instruction']}\\n{item['input']}\"\n",
        "        else:\n",
        "            question = item['instruction']\n",
        "        truth = item['output']\n",
        "\n",
        "        model_answer = generate_func(question)\n",
        "        f1 = f1_word_overlap(model_answer, truth)\n",
        "        rouge_l = rouge_l_score(model_answer, truth)\n",
        "        codebleu = codebleu_score(model_answer, truth)\n",
        "\n",
        "        results.append({\n",
        "            \"question\": question,\n",
        "            \"truth\": truth,\n",
        "            \"model_answer\": model_answer,\n",
        "            \"f1_score\": f1,\n",
        "            \"rouge_l_score\": rouge_l,\n",
        "            \"codebleu_score\": codebleu\n",
        "        })\n",
        "\n",
        "    avg_f1 = sum(r[\"f1_score\"] for r in results) / len(results)\n",
        "    avg_rouge_l = sum(r[\"rouge_l_score\"] for r in results) / len(results)\n",
        "    avg_codebleu = sum(r[\"codebleu_score\"] for r in results) / len(results)\n",
        "    print('\\n')\n",
        "    print(f\"\\nAverage CodeBLEU Score   : {avg_codebleu:.4f}\")\n",
        "    print(f\"Average F1 Overlap Score: {avg_f1:.4f}\")\n",
        "    print(f\"Average ROUGE-L Score   : {avg_rouge_l:.4f}\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "OiQkFE3v69YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base"
      ],
      "metadata": {
        "id": "EraJ1O6jDEZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = benchmark_model(test_data, generate_answer_alpaca_style1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTAbzkmN7Bp6",
        "outputId": "e5ffe1d3-86bb-4572-d1c2-1bbc18658914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [48:50<00:00,  9.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Average CodeBLEU Score   : 0.1922\n",
            "Average F1 Overlap Score: 0.1203\n",
            "Average ROUGE-L Score   : 0.0498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lora"
      ],
      "metadata": {
        "id": "sMJZVcn3DGfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model = benchmark_model(test_data, generate_answer_alpaca_style)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-rr7OsR8lDt",
        "outputId": "154a04aa-5831-489f-8518-67d3bbc6647e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [34:37<00:00,  6.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Average CodeBLEU Score   : 0.6522\n",
            "Average F1 Overlap Score: 0.5522\n",
            "Average ROUGE-L Score   : 0.4842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "metrics = ['Avg CodeBLEU', 'Avg F1-Overlap', 'Avg ROUGE-L']\n",
        "metric_descriptions = [\n",
        "    \"Measures similarity between generated and reference code\",\n",
        "    \"Evaluates token-level overlap between predictions and references\",\n",
        "    \"Measures longest common subsequence between texts\"\n",
        "]\n",
        "base_scores = [0.1922, 0.1203, 0.0498]\n",
        "lora_scores = [0.6522, 0.5522, 0.4842]\n",
        "improvement = [(l/b) for b,l in zip(base_scores,lora_scores)]\n",
        "\n",
        "# Training metrics\n",
        "\n",
        "trainvval_desc = \"Train loss measures errors on training data, val loss on <br> validation data; a small gap indicates good model learning.\"\n",
        "perplexity_desc = \"The closer to 1, the more accurate the LLM's predictions.\"\n",
        "\n",
        "train_loss = 0.0314\n",
        "eval_loss = 0.0312\n",
        "perplexity = 1.03\n",
        "\n",
        "# Color Palette\n",
        "COLORS = {\n",
        "    'dark_bg': '#0f0f13',\n",
        "    'darker_bg': '#08080b',\n",
        "    'accent_blue': '#00f5ff',\n",
        "    'accent_pink': '#ff00f5',\n",
        "    'accent_purple': '#610C9F',\n",
        "    'gradient_fire': '#F05941',\n",
        "    'gradient_ocean': '#1D267D',\n",
        "    'text': '#ffffff',\n",
        "    'grid': 'rgba(255, 255, 255, 0.05)',\n",
        "    'highlight': '#ffd700'\n",
        "}\n",
        "\n",
        "# Create figure with custom layout\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    row_heights=[0.7, 0.3],\n",
        "    column_widths=[0.6, 0.4],\n",
        "    vertical_spacing=0.15,\n",
        "    horizontal_spacing=0.15,\n",
        "    specs=[\n",
        "        [{\"type\": \"bar\", \"colspan\": 2}, None],\n",
        "        [{\"type\": \"bar\"}, {\"type\": \"bar\"}]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Main Bars (top row)\n",
        "fig.add_trace(go.Bar(\n",
        "    x=metrics,\n",
        "    y=base_scores,\n",
        "    name='Base Model',\n",
        "    marker_color=COLORS['accent_blue'],\n",
        "    marker_line_color='rgba(255,255,255,0.8)',\n",
        "    marker_line_width=1,\n",
        "    opacity=0.9,\n",
        "    text=[f'<b>{score:.3f}</b>' for score in base_scores],\n",
        "    textposition='outside',\n",
        "    textfont=dict(color=COLORS['text'], size=14),\n",
        "    hoverinfo='y+name'\n",
        "), row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=metrics,\n",
        "    y=lora_scores,\n",
        "    name='LoRA Model',\n",
        "    marker_color=COLORS['accent_pink'],\n",
        "    marker_line_color='rgba(255,255,255,0.8)',\n",
        "    marker_line_width=1,\n",
        "    opacity=0.9,\n",
        "    text=[f'<b>{score:.3f}</b>' for score in lora_scores],\n",
        "    textposition='outside',\n",
        "    textfont=dict(color=COLORS['text'], size=14),\n",
        "    hoverinfo='y+name'\n",
        "), row=1, col=1)\n",
        "\n",
        "# Improvement bars (bottom left)\n",
        "fig.add_trace(go.Bar(\n",
        "    x=metrics,\n",
        "    y=improvement,\n",
        "    name='Improvement',\n",
        "    marker_line_width=1,\n",
        "    marker_color=COLORS['accent_purple'],\n",
        "    marker_line_color='rgba(255,255,255,0.5)',\n",
        "    text=[f'<b>{imp:.2f}x</b>' for imp in improvement],\n",
        "    textposition='inside',\n",
        "    textfont=dict(color=COLORS['highlight'], size=14, family=\"Arial Black\"),\n",
        "    hoverinfo='y+name'\n",
        "), row=2, col=1)\n",
        "\n",
        "# Training metrics (bottom right)\n",
        "fig.add_trace(go.Bar(\n",
        "    x=['Train Loss', 'Eval Loss'],\n",
        "    y=[train_loss, eval_loss],\n",
        "    name='Training Metrics',\n",
        "    marker_color=[COLORS['gradient_fire'], COLORS['gradient_ocean']],\n",
        "    marker_line_color='rgba(255,255,255,0.8)',\n",
        "    marker_line_width=1,\n",
        "    text=[f'<b>{train_loss:.4f}</b>', f'<b>{eval_loss:.4f}</b>'],\n",
        "    textposition='auto',\n",
        "    textfont=dict(color=COLORS['text'], size=14),\n",
        "), row=2, col=2)\n",
        "\n",
        "\n",
        "# Custom Layout\n",
        "fig.update_layout(\n",
        "    height=900,\n",
        "    template='plotly_dark',\n",
        "    plot_bgcolor=COLORS['dark_bg'],\n",
        "    paper_bgcolor=COLORS['darker_bg'],\n",
        "    title={\n",
        "        'text': \"<b>LoRA Fine Tuning Qwen2.5-7b Evaluation</b>\",\n",
        "        'y':0.95,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top',\n",
        "        'font': {'size': 28, 'color': COLORS['text'], 'family': \"Arial Black\"},\n",
        "    },\n",
        "    xaxis=dict(\n",
        "        title='<b>EVALUATION METRICS</b>',\n",
        "        titlefont=dict(size=18, color=COLORS['text'], family=\"Arial Black\"),\n",
        "        tickfont=dict(size=14, color=COLORS['text']),\n",
        "        gridcolor=COLORS['grid'],\n",
        "        linecolor=COLORS['grid'],\n",
        "        showgrid=False\n",
        "    ),\n",
        "    xaxis2=dict(\n",
        "        showgrid=False,\n",
        "        tickfont=dict(size=14, color=COLORS['text'])\n",
        "    ),\n",
        "    xaxis3=dict(\n",
        "        title='<b>TRAINING METRICS</b>',\n",
        "        titlefont=dict(size=14, color=COLORS['text'], family=\"Arial Black\"),\n",
        "        tickfont=dict(size=12, color=COLORS['text']),\n",
        "        gridcolor=COLORS['grid'],\n",
        "        showgrid=False\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='<b>SCORE</b>',\n",
        "        titlefont=dict(size=16, color=COLORS['text'], family=\"Arial Black\"),\n",
        "        tickfont=dict(size=12, color=COLORS['text']),\n",
        "        gridcolor=COLORS['grid'],\n",
        "        range=[0, 0.8],\n",
        "        dtick=0.2\n",
        "    ),\n",
        "    yaxis2=dict(\n",
        "        title='<b>IMPROVEMENT </b>',\n",
        "        titlefont=dict(size=16, color=COLORS['text'], family=\"Arial Black\"),\n",
        "        tickfont=dict(size=12, color=COLORS['text']),\n",
        "        gridcolor=COLORS['grid'],\n",
        "        range=[0, max(improvement)*1.2]\n",
        "    ),\n",
        "    yaxis3=dict(\n",
        "        title='<b>LOSS</b>',\n",
        "        titlefont=dict(size=14, color=COLORS['text'], family=\"Arial Black\"),\n",
        "        tickfont=dict(size=12, color=COLORS['text']),\n",
        "        gridcolor=COLORS['grid'],\n",
        "        range=[0, max(train_loss, eval_loss)*1.5]\n",
        "    ),\n",
        "    legend=dict(\n",
        "        orientation=\"h\",\n",
        "        yanchor=\"bottom\",\n",
        "        y=1.02,\n",
        "        xanchor=\"center\",\n",
        "        x=0.5,\n",
        "        font=dict(size=14, color=COLORS['text'], family=\"Arial Black\"),\n",
        "        bgcolor='rgba(0,0,0,0)'\n",
        "    ),\n",
        "    barmode='group',\n",
        "    bargap=0.4,\n",
        "    bargroupgap=0.1,\n",
        "    margin=dict(l=80, r=80, t=150, b=200),\n",
        "    hoverlabel=dict(\n",
        "        bgcolor='rgba(15,15,25,0.9)',\n",
        "        font_size=14,\n",
        "        font_family=\"Arial\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Metric descriptions\n",
        "for i, (metric, desc) in enumerate(zip(metrics, metric_descriptions)):\n",
        "    fig.add_annotation(\n",
        "        x=-1,\n",
        "        y = {0: -0.07, 1: -0.10, 2: -0.13}.get(i, None),\n",
        "        xref=\"x\",\n",
        "        yref=\"paper\",\n",
        "        text=f\"<b>{metric} : </b>{desc}\",\n",
        "        showarrow=False,\n",
        "        font=dict(size=12, color='rgba(255,255,255,0.8)'),\n",
        "        xanchor=\"left\",\n",
        "        yanchor=\"top\",\n",
        "        align=\"left\"\n",
        "    )\n",
        "\n",
        "# Performance highlights\n",
        "fig.add_annotation(\n",
        "    x=0.5, y=1.125,\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    text=f\"🔥 LoRA achieves : <span style='color:#ffd700'>{np.round(lora_scores[0]/base_scores[0],1)}x</span> better CodeBLEU, <span style='color:#ffd700'>{np.round(lora_scores[1]/base_scores[1],1)}x</span> better F1, and <span style='color:#ffd700'>{np.round(lora_scores[2]/base_scores[2],1)}x</span> better ROUGE-L, Perplexity: <span style='color:{COLORS['highlight']}'>{perplexity:.2f}</span>\",\n",
        "    showarrow=False,\n",
        "    font=dict(size=16, color=COLORS['text'], family=\"Arial\"),\n",
        "    align=\"center\",\n",
        "    bgcolor=\"rgba(138, 43, 226, 0.2)\",\n",
        "    bordercolor=COLORS['accent_purple']\n",
        ")\n",
        "\n",
        "# Add perplexity as text annotation in the bottom right\n",
        "fig.add_annotation(\n",
        "    x=0.6, y=-0.25,\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    text=f\"<b>Perplexity:</b> {perplexity_desc}\",\n",
        "    showarrow=False,\n",
        "    font=dict(size=12, color='rgba(255,255,255,0.8)'),\n",
        "    xanchor=\"left\",\n",
        "    yanchor=\"top\",\n",
        "    align=\"left\"\n",
        "\n",
        ")\n",
        "\n",
        "fig.add_annotation(\n",
        "    x=0.8, y=-0.11,\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    text=f\"<b>Train Loss vs Val loss:</b><br> {trainvval_desc}\",\n",
        "    showarrow=False,\n",
        "    font=dict(size=12, color='rgba(255,255,255,0.8)'),\n",
        "    xanchor=\"center\",\n",
        "    yanchor=\"top\",\n",
        "    align=\"center\"\n",
        "\n",
        ")\n",
        "\n",
        "# Tech stack and signature\n",
        "fig.add_annotation(\n",
        "    x=0.2, y=-0.35,\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    text=\"<b>Tech Stack:</b> PyTorch | Unsloth | Transformer | LoRA (Low-Rank Adaptation) | Plotly\",\n",
        "    showarrow=False,\n",
        "    font=dict(size=12, color='rgba(255,255,255,0.7)'),\n",
        "    xanchor=\"center\"\n",
        ")\n",
        "\n",
        "# Tech stack and signature\n",
        "fig.add_annotation(\n",
        "    x=0.22, y=-0.27,\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    text=\"<b>40 million</b> Trainable parameters (0.58% from 7 billion parameters)\",\n",
        "    showarrow=False,\n",
        "    font=dict(size=12, color='rgba(255,255,255,0.7)'),\n",
        "    xanchor=\"center\"\n",
        ")\n",
        "fig.add_annotation(\n",
        "    x=0.215, y=-0.24,\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    text=\"<b>Datasets</b> 4700 rows training, 300 rows validation, alpaca format\",\n",
        "    showarrow=False,\n",
        "    font=dict(size=12, color='rgba(255,255,255,0.7)'),\n",
        "    xanchor=\"center\"\n",
        ")\n",
        "\n",
        "fig.add_annotation(\n",
        "    x=0, y=1,\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    text=\"higher score = better performance.\",\n",
        "    showarrow=False,\n",
        "    font=dict(size=12, color='rgba(255,255,255,0.8)'),\n",
        "    xanchor=\"left\",\n",
        "    yanchor=\"top\",\n",
        "    align=\"left\"\n",
        ")\n",
        "\n",
        "fig.add_annotation(\n",
        "    x=1.05, y=-0.35,\n",
        "    xref=\"paper\", yref=\"paper\",\n",
        "    text=\"🔗 @ardiannurcahya | #AIModels #ParameterEfficientFineTuning\",\n",
        "    showarrow=False,\n",
        "    font=dict(size=12, color='rgba(255,255,255,0.7)'),\n",
        "    xanchor=\"right\"\n",
        ")\n",
        "\n",
        "# Add glow effects\n",
        "for i in range(len(metrics)):\n",
        "    fig.add_shape(type=\"rect\",\n",
        "        xref=\"x\", yref=\"y\",\n",
        "        x0=i-0.4, y0=0,\n",
        "        x1=i+0.4, y1=max(lora_scores),\n",
        "        line=dict(width=0),\n",
        "        fillcolor=COLORS['accent_pink'],\n",
        "        opacity=0.03,\n",
        "        layer=\"below\"\n",
        "    )\n",
        "\n",
        "# Add glow effects\n",
        "for i in range(len(metrics)):\n",
        "    fig.add_shape(type=\"rect\",\n",
        "        xref=\"x\", yref=\"y\",\n",
        "        x0=i-0.4, y0=0,\n",
        "        x1=i+0.4, y1=max(lora_scores),\n",
        "        line=dict(width=0),\n",
        "        fillcolor=COLORS['accent_pink'],\n",
        "        opacity=0.03,\n",
        "        layer=\"below\"\n",
        "    )\n",
        "\n",
        "# Apply rounded corners to all bars\n",
        "for trace in fig.data:\n",
        "    if trace.type == 'bar':\n",
        "        trace.marker.line.width = 1.5\n",
        "        trace.marker.cornerradius = 5\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "3mMQN-JHipXk",
        "outputId": "ecdbb64e-4a50-40d9-8753-55efa2158f16"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ba2b240f-2f76-42cf-a196-9b1d23acaf8a\" class=\"plotly-graph-div\" style=\"height:900px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ba2b240f-2f76-42cf-a196-9b1d23acaf8a\")) {                    Plotly.newPlot(                        \"ba2b240f-2f76-42cf-a196-9b1d23acaf8a\",                        [{\"hoverinfo\":\"y+name\",\"marker\":{\"color\":\"#00f5ff\",\"line\":{\"color\":\"rgba(255,255,255,0.8)\",\"width\":1.5},\"cornerradius\":5},\"name\":\"Base Model\",\"opacity\":0.9,\"text\":[\"\\u003cb\\u003e0.192\\u003c\\u002fb\\u003e\",\"\\u003cb\\u003e0.120\\u003c\\u002fb\\u003e\",\"\\u003cb\\u003e0.050\\u003c\\u002fb\\u003e\"],\"textfont\":{\"color\":\"#ffffff\",\"size\":14},\"textposition\":\"outside\",\"x\":[\"Avg CodeBLEU\",\"Avg F1-Overlap\",\"Avg ROUGE-L\"],\"y\":[0.1922,0.1203,0.0498],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hoverinfo\":\"y+name\",\"marker\":{\"color\":\"#ff00f5\",\"line\":{\"color\":\"rgba(255,255,255,0.8)\",\"width\":1.5},\"cornerradius\":5},\"name\":\"LoRA Model\",\"opacity\":0.9,\"text\":[\"\\u003cb\\u003e0.652\\u003c\\u002fb\\u003e\",\"\\u003cb\\u003e0.552\\u003c\\u002fb\\u003e\",\"\\u003cb\\u003e0.484\\u003c\\u002fb\\u003e\"],\"textfont\":{\"color\":\"#ffffff\",\"size\":14},\"textposition\":\"outside\",\"x\":[\"Avg CodeBLEU\",\"Avg F1-Overlap\",\"Avg ROUGE-L\"],\"y\":[0.6522,0.5522,0.4842],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"hoverinfo\":\"y+name\",\"marker\":{\"color\":\"#610C9F\",\"line\":{\"color\":\"rgba(255,255,255,0.5)\",\"width\":1.5},\"cornerradius\":5},\"name\":\"Improvement\",\"text\":[\"\\u003cb\\u003e3.39x\\u003c\\u002fb\\u003e\",\"\\u003cb\\u003e4.59x\\u003c\\u002fb\\u003e\",\"\\u003cb\\u003e9.72x\\u003c\\u002fb\\u003e\"],\"textfont\":{\"color\":\"#ffd700\",\"family\":\"Arial Black\",\"size\":14},\"textposition\":\"inside\",\"x\":[\"Avg CodeBLEU\",\"Avg F1-Overlap\",\"Avg ROUGE-L\"],\"y\":[3.3933402705515086,4.59019118869493,9.72289156626506],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[\"#F05941\",\"#1D267D\"],\"line\":{\"color\":\"rgba(255,255,255,0.8)\",\"width\":1.5},\"cornerradius\":5},\"name\":\"Training Metrics\",\"text\":[\"\\u003cb\\u003e0.0314\\u003c\\u002fb\\u003e\",\"\\u003cb\\u003e0.0312\\u003c\\u002fb\\u003e\"],\"textfont\":{\"color\":\"#ffffff\",\"size\":14},\"textposition\":\"auto\",\"x\":[\"Train Loss\",\"Eval Loss\"],\"y\":[0.0314,0.0312],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"lakecolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#506784\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"dark\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"bordercolor\":\"rgb(17,17,17)\",\"borderwidth\":1,\"tickwidth\":0},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\\u003cb\\u003eEVALUATION METRICS\\u003c\\u002fb\\u003e\",\"font\":{\"size\":18,\"color\":\"#ffffff\",\"family\":\"Arial Black\"}},\"tickfont\":{\"size\":14,\"color\":\"#ffffff\"},\"gridcolor\":\"rgba(255, 255, 255, 0.05)\",\"linecolor\":\"rgba(255, 255, 255, 0.05)\",\"showgrid\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.405,1.0],\"title\":{\"text\":\"\\u003cb\\u003eSCORE\\u003c\\u002fb\\u003e\",\"font\":{\"size\":16,\"color\":\"#ffffff\",\"family\":\"Arial Black\"}},\"tickfont\":{\"size\":12,\"color\":\"#ffffff\"},\"gridcolor\":\"rgba(255, 255, 255, 0.05)\",\"range\":[0,0.8],\"dtick\":0.2},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.51],\"tickfont\":{\"size\":14,\"color\":\"#ffffff\"},\"showgrid\":false},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.255],\"title\":{\"text\":\"\\u003cb\\u003eIMPROVEMENT \\u003c\\u002fb\\u003e\",\"font\":{\"size\":16,\"color\":\"#ffffff\",\"family\":\"Arial Black\"}},\"tickfont\":{\"size\":12,\"color\":\"#ffffff\"},\"gridcolor\":\"rgba(255, 255, 255, 0.05)\",\"range\":[0,11.667469879518071]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.66,1.0],\"title\":{\"text\":\"\\u003cb\\u003eTRAINING METRICS\\u003c\\u002fb\\u003e\",\"font\":{\"size\":14,\"color\":\"#ffffff\",\"family\":\"Arial Black\"}},\"tickfont\":{\"size\":12,\"color\":\"#ffffff\"},\"gridcolor\":\"rgba(255, 255, 255, 0.05)\",\"showgrid\":false},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.255],\"title\":{\"text\":\"\\u003cb\\u003eLOSS\\u003c\\u002fb\\u003e\",\"font\":{\"size\":14,\"color\":\"#ffffff\",\"family\":\"Arial Black\"}},\"tickfont\":{\"size\":12,\"color\":\"#ffffff\"},\"gridcolor\":\"rgba(255, 255, 255, 0.05)\",\"range\":[0,0.047099999999999996]},\"title\":{\"font\":{\"size\":28,\"color\":\"#ffffff\",\"family\":\"Arial Black\"},\"text\":\"\\u003cb\\u003eLoRA Fine Tuning Qwen2.5-7b Evaluation\\u003c\\u002fb\\u003e\",\"y\":0.95,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"legend\":{\"font\":{\"size\":14,\"color\":\"#ffffff\",\"family\":\"Arial Black\"},\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"center\",\"x\":0.5,\"bgcolor\":\"rgba(0,0,0,0)\"},\"margin\":{\"l\":80,\"r\":80,\"t\":150,\"b\":200},\"hoverlabel\":{\"font\":{\"size\":14,\"family\":\"Arial\"},\"bgcolor\":\"rgba(15,15,25,0.9)\"},\"height\":900,\"plot_bgcolor\":\"#0f0f13\",\"paper_bgcolor\":\"#08080b\",\"barmode\":\"group\",\"bargap\":0.4,\"bargroupgap\":0.1,\"annotations\":[{\"align\":\"left\",\"font\":{\"color\":\"rgba(255,255,255,0.8)\",\"size\":12},\"showarrow\":false,\"text\":\"\\u003cb\\u003eAvg CodeBLEU : \\u003c\\u002fb\\u003eMeasures similarity between generated and reference code\",\"x\":-1,\"xanchor\":\"left\",\"xref\":\"x\",\"y\":-0.07,\"yanchor\":\"top\",\"yref\":\"paper\"},{\"align\":\"left\",\"font\":{\"color\":\"rgba(255,255,255,0.8)\",\"size\":12},\"showarrow\":false,\"text\":\"\\u003cb\\u003eAvg F1-Overlap : \\u003c\\u002fb\\u003eEvaluates token-level overlap between predictions and references\",\"x\":-1,\"xanchor\":\"left\",\"xref\":\"x\",\"y\":-0.1,\"yanchor\":\"top\",\"yref\":\"paper\"},{\"align\":\"left\",\"font\":{\"color\":\"rgba(255,255,255,0.8)\",\"size\":12},\"showarrow\":false,\"text\":\"\\u003cb\\u003eAvg ROUGE-L : \\u003c\\u002fb\\u003eMeasures longest common subsequence between texts\",\"x\":-1,\"xanchor\":\"left\",\"xref\":\"x\",\"y\":-0.13,\"yanchor\":\"top\",\"yref\":\"paper\"},{\"align\":\"center\",\"bgcolor\":\"rgba(138, 43, 226, 0.2)\",\"bordercolor\":\"#610C9F\",\"font\":{\"color\":\"#ffffff\",\"family\":\"Arial\",\"size\":16},\"showarrow\":false,\"text\":\"🔥 LoRA achieves : \\u003cspan style='color:#ffd700'\\u003e3.4x\\u003c\\u002fspan\\u003e better CodeBLEU, \\u003cspan style='color:#ffd700'\\u003e4.6x\\u003c\\u002fspan\\u003e better F1, and \\u003cspan style='color:#ffd700'\\u003e9.7x\\u003c\\u002fspan\\u003e better ROUGE-L, Perplexity: \\u003cspan style='color:#ffd700'\\u003e1.03\\u003c\\u002fspan\\u003e\",\"x\":0.5,\"xref\":\"paper\",\"y\":1.125,\"yref\":\"paper\"},{\"align\":\"left\",\"font\":{\"color\":\"rgba(255,255,255,0.8)\",\"size\":12},\"showarrow\":false,\"text\":\"\\u003cb\\u003ePerplexity:\\u003c\\u002fb\\u003e The closer to 1, the more accurate the LLM's predictions.\",\"x\":0.6,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":-0.25,\"yanchor\":\"top\",\"yref\":\"paper\"},{\"align\":\"center\",\"font\":{\"color\":\"rgba(255,255,255,0.8)\",\"size\":12},\"showarrow\":false,\"text\":\"\\u003cb\\u003eTrain Loss vs Val loss:\\u003c\\u002fb\\u003e\\u003cbr\\u003e Train loss measures errors on training data, val loss on \\u003cbr\\u003e validation data; a small gap indicates good model learning.\",\"x\":0.8,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":-0.11,\"yanchor\":\"top\",\"yref\":\"paper\"},{\"font\":{\"color\":\"rgba(255,255,255,0.7)\",\"size\":12},\"showarrow\":false,\"text\":\"\\u003cb\\u003eTech Stack:\\u003c\\u002fb\\u003e PyTorch | Unsloth | Transformer | LoRA (Low-Rank Adaptation) | Plotly\",\"x\":0.2,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":-0.35,\"yref\":\"paper\"},{\"font\":{\"color\":\"rgba(255,255,255,0.7)\",\"size\":12},\"showarrow\":false,\"text\":\"\\u003cb\\u003e40 million\\u003c\\u002fb\\u003e Trainable parameters (0.58% from 7 billion parameters)\",\"x\":0.22,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":-0.27,\"yref\":\"paper\"},{\"font\":{\"color\":\"rgba(255,255,255,0.7)\",\"size\":12},\"showarrow\":false,\"text\":\"\\u003cb\\u003eDatasets\\u003c\\u002fb\\u003e 4700 rows training, 300 rows validation, alpaca format\",\"x\":0.215,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":-0.24,\"yref\":\"paper\"},{\"align\":\"left\",\"font\":{\"color\":\"rgba(255,255,255,0.8)\",\"size\":12},\"showarrow\":false,\"text\":\"higher score = better performance.\",\"x\":0,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":1,\"yanchor\":\"top\",\"yref\":\"paper\"},{\"font\":{\"color\":\"rgba(255,255,255,0.7)\",\"size\":12},\"showarrow\":false,\"text\":\"🔗 @ardiannurcahya | #AIModels #ParameterEfficientFineTuning\",\"x\":1.05,\"xanchor\":\"right\",\"xref\":\"paper\",\"y\":-0.35,\"yref\":\"paper\"}],\"shapes\":[{\"fillcolor\":\"#ff00f5\",\"layer\":\"below\",\"line\":{\"width\":0},\"opacity\":0.03,\"type\":\"rect\",\"x0\":-0.4,\"x1\":0.4,\"xref\":\"x\",\"y0\":0,\"y1\":0.6522,\"yref\":\"y\"},{\"fillcolor\":\"#ff00f5\",\"layer\":\"below\",\"line\":{\"width\":0},\"opacity\":0.03,\"type\":\"rect\",\"x0\":0.6,\"x1\":1.4,\"xref\":\"x\",\"y0\":0,\"y1\":0.6522,\"yref\":\"y\"},{\"fillcolor\":\"#ff00f5\",\"layer\":\"below\",\"line\":{\"width\":0},\"opacity\":0.03,\"type\":\"rect\",\"x0\":1.6,\"x1\":2.4,\"xref\":\"x\",\"y0\":0,\"y1\":0.6522,\"yref\":\"y\"},{\"fillcolor\":\"#ff00f5\",\"layer\":\"below\",\"line\":{\"width\":0},\"opacity\":0.03,\"type\":\"rect\",\"x0\":-0.4,\"x1\":0.4,\"xref\":\"x\",\"y0\":0,\"y1\":0.6522,\"yref\":\"y\"},{\"fillcolor\":\"#ff00f5\",\"layer\":\"below\",\"line\":{\"width\":0},\"opacity\":0.03,\"type\":\"rect\",\"x0\":0.6,\"x1\":1.4,\"xref\":\"x\",\"y0\":0,\"y1\":0.6522,\"yref\":\"y\"},{\"fillcolor\":\"#ff00f5\",\"layer\":\"below\",\"line\":{\"width\":0},\"opacity\":0.03,\"type\":\"rect\",\"x0\":1.6,\"x1\":2.4,\"xref\":\"x\",\"y0\":0,\"y1\":0.6522,\"yref\":\"y\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ba2b240f-2f76-42cf-a196-9b1d23acaf8a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}